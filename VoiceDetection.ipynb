{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audiosegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webrtcvad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aynur/Installed/miniconda3/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "from collections.abc import Iterable\n",
    "import noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 32000\n",
    "SAMPLE_WIDTH = 1./SAMPLE_RATE\n",
    "FRAME_DURATION = 0.01\n",
    "FRAME_WIDTH = int(SAMPLE_RATE * FRAME_DURATION)\n",
    "MIN_FREQ = 1./FRAME_DURATION\n",
    "\n",
    "def FREQ_BY_NUM(i):\n",
    "    return MIN_FREQ * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT(frame):\n",
    "    fft = np.abs(np.fft.rfft(frame).real)\n",
    "    return fft\n",
    "\n",
    "def CUTFFT(fft, max_freq):\n",
    "    return fft[:int(max_freq*FRAME_DURATION)]\n",
    "\n",
    "def SIGNAL_MEAN(signal):\n",
    "    return np.mean(signal)\n",
    "\n",
    "def SIGNAL_GEOM_MEAN(signal):\n",
    "    return np.exp(np.sum(np.log(1e-11 + signal))/len(signal))\n",
    "\n",
    "def FFT_MAX_FREQ(fft):\n",
    "    return FREQ_BY_NUM(np.argmax(fft))\n",
    "\n",
    "def SFM(fft):\n",
    "    return 10 * np.log10(1e-11 + SIGNAL_GEOM_MEAN(fft)/(1e-11 + SIGNAL_MEAN(fft)))\n",
    "    \n",
    "def ENERGY(signal):\n",
    "    return SAMPLE_WIDTH*np.sum(signal.real**2) #\n",
    "\n",
    "def IDENTITY(fft):\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Characteristic:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.value = []\n",
    "        \n",
    "    def add_frame(self, frame):\n",
    "        self.value.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Silence:\n",
    "    def __init__(self, agr=1, chars=()):\n",
    "        self.vad = webrtcvad.Vad(agr)\n",
    "        self.values = []\n",
    "        self.chars=chars\n",
    "        \n",
    "    def is_voice(self, frame):\n",
    "        val = self.vad.is_speech(frame, SAMPLE_RATE)\n",
    "        self.values.append(1.*val)\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTPlot:\n",
    "    def __init__(self, silence, frame_duration=FRAME_DURATION, max_duration=10):\n",
    "        self.silence = silence\n",
    "        self.frame_duration = frame_duration\n",
    "        self.max_duration = max_duration\n",
    "        self.fig, self.ax = plt.subplots(len(silence.chars) + 1, 1, sharex=True)\n",
    "        self.fig.show()\n",
    "    \n",
    "    def plot(self, current_time):\n",
    "        start_time = max(0., current_time - self.max_duration)\n",
    "        frame_start, frame_end = int(start_time/self.frame_duration), int(current_time/self.frame_duration)\n",
    "        for i, v in enumerate(self.silence.chars):\n",
    "            self.ax[i].cla()\n",
    "            value = v.value[frame_start:frame_end]\n",
    "            if len(value) == 0: continue\n",
    "            if isinstance(value[0], Iterable) > 0:\n",
    "                extent = [start_time, current_time, 0, 1]\n",
    "                self.ax[i].imshow(np.swapaxes(np.array(value), 0, 1), cmap=plt.get_cmap('hot'), aspect='auto', origin='lower', interpolation=None, extent=extent, vmin=0)\n",
    "            else:\n",
    "                x = [start_time + self.frame_duration*j for j in range(len(value))]\n",
    "                self.ax[i].plot(x, value, 'b-')\n",
    "                thr = v.kwargs.get('threshold', None)\n",
    "                if thr is not None: self.ax[i].plot([x[0], x[-1]], [thr, thr], 'r-')\n",
    "            self.ax[i].set_xlabel(\"time, s\")\n",
    "            self.ax[i].set_ylabel(v.name)\n",
    "        self.ax[-1].cla()\n",
    "        self.ax[-1].set_xlabel('voice (=1), silence(=0)')\n",
    "        value = self.silence.values[frame_start:frame_end]\n",
    "        self.ax[-1].plot([start_time + self.frame_duration*j for j in range(len(value))], value, 'g-')\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import time\n",
    "\n",
    "\n",
    "p=pyaudio.PyAudio()\n",
    "stream=p.open(format=pyaudio.paInt16, channels=1, rate=SAMPLE_RATE, input=True, frames_per_buffer=FRAME_WIDTH)\n",
    "\n",
    "DURATION = 10\n",
    "PLOT_EVERY = 1\n",
    "ESTIMATION_TIME = 0.3\n",
    "import wave\n",
    "\n",
    "noise_wav = wave.open(\"noise.wav\", 'rb')\n",
    "noise_data = noise_wav.readframes(-1)\n",
    "\n",
    "\n",
    "wavefile = wave.open(\"tmp.wav\", \"wb\")\n",
    "wavefile.setnchannels(1)\n",
    "wavefile.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "wavefile.setframerate(SAMPLE_RATE)\n",
    "\n",
    "MAX_FREQ = 8000\n",
    "VOICE_FREQS = (100, 1500)\n",
    "\n",
    "silence = Silence(agr=3, chars=[Characteristic(\"FFT\")])\n",
    "plot = RTPlot(silence, frame_duration=FRAME_DURATION, max_duration=10)\n",
    "\n",
    "\n",
    "for i in range(int(DURATION/FRAME_DURATION)):\n",
    "    current_time = i * FRAME_DURATION\n",
    "    rawdata = stream.read(FRAME_WIDTH)\n",
    "    \n",
    "    \n",
    "    \n",
    "    wavefile.writeframes(rawdata)\n",
    "    data = np.array(np.frombuffer(rawdata, dtype=np.int16), dtype='float32')\n",
    "    reduced_voice = noisereduce.reduce_noise(audio_clip=data, noise_clip=np.array(np.frombuffer(noise_data, dtype=np.int16), dtype='float32'), verbose=False)\n",
    "    print(reduced_voice)\n",
    "    fft = FFT(data)\n",
    "    signal = CUTFFT(fft, MAX_FREQ)\n",
    "    \n",
    "    silence.is_voice(rawdata)\n",
    "    for c in silence.chars:\n",
    "        c.add_frame(signal)\n",
    "    \n",
    "    if i % int(PLOT_EVERY/FRAME_DURATION) == 0:\n",
    "        plot.plot(current_time)\n",
    "    \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
