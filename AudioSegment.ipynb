{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audiosegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 32000\n",
    "SAMPLE_WIDTH = 1./SAMPLE_RATE\n",
    "FRAME_DURATION = 4\n",
    "FRAME_WIDTH = int(SAMPLE_RATE * FRAME_DURATION)\n",
    "MIN_FREQ = 1./FRAME_DURATION\n",
    "\n",
    "def FREQ_BY_NUM(i):\n",
    "    return MIN_FREQ * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT(frame):\n",
    "    fft = np.abs(np.fft.rfft(frame).real)\n",
    "    return fft\n",
    "\n",
    "def CUTFFT(fft, max_freq):\n",
    "    return fft[:int(max_freq*FRAME_DURATION)]\n",
    "\n",
    "def SIGNAL_MEAN(signal):\n",
    "    return np.mean(signal)\n",
    "\n",
    "def SIGNAL_GEOM_MEAN(signal):\n",
    "    return np.exp(np.sum(np.log(1e-11 + signal))/len(signal))\n",
    "\n",
    "def FFT_MAX_FREQ(fft):\n",
    "    return FREQ_BY_NUM(np.argmax(fft))\n",
    "\n",
    "def SFM(fft):\n",
    "    return 10 * np.log10(1e-11 + SIGNAL_GEOM_MEAN(fft)/(1e-11 + SIGNAL_MEAN(fft)))\n",
    "    \n",
    "def ENERGY(signal):\n",
    "    return SAMPLE_WIDTH*np.sum(signal.real**2) #\n",
    "\n",
    "def IDENTITY(fft):\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[: 1 channels, 16 bit, sampled @ 32.0 kHz, 0.240s long, : 1 channels, 16 bit, sampled @ 32.0 kHz, 0.240s long, : 1 channels, 16 bit, sampled @ 32.0 kHz, 0.060s long]\n",
      "Reducing unvoiced segments to a single wav file 'unvoiced.wav'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5c589121ca0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDURATION\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFRAME_DURATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFRAME_DURATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFRAME_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdata_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/miniconda3/lib/python3.7/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import time\n",
    "import wave\n",
    "\n",
    "p=pyaudio.PyAudio()\n",
    "stream=p.open(format=pyaudio.paInt16, channels=1, rate=SAMPLE_RATE, input=True, frames_per_buffer=FRAME_WIDTH)\n",
    "\n",
    "DURATION = 10\n",
    "PLOT_EVERY = 1\n",
    "\n",
    "\n",
    "wavefile = wave.open(\"tmp.wav\", \"wb\")\n",
    "wavefile.setnchannels(1)\n",
    "wavefile.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "wavefile.setframerate(SAMPLE_RATE)\n",
    "\n",
    "\n",
    "for i in range(int(DURATION/FRAME_DURATION)):\n",
    "    current_time = i * FRAME_DURATION\n",
    "    rawdata = stream.read(FRAME_WIDTH)\n",
    "    data_int = np.frombuffer(rawdata, dtype=np.int16)\n",
    "    data = np.array(data_int, dtype='float32')\n",
    "    seg = audiosegment.from_numpy_array(data_int, framerate=SAMPLE_RATE)\n",
    "    results = seg.detect_voice()\n",
    "    voiced = [tup[1] for tup in results if tup[0] == 'v']\n",
    "    unvoiced = [tup[1] for tup in results if tup[0] == 'u']\n",
    "    print(voiced)\n",
    "    wavefile.writeframes(rawdata)\n",
    "    voiced_segment = voiced[0].reduce(voiced[1:])\n",
    "    voiced_segment.export(f\"{i}voiced.wav\", format=\"WAV\")\n",
    "    print(\"Reducing unvoiced segments to a single wav file 'unvoiced.wav'\")\n",
    "    unvoiced_segment = unvoiced[0].reduce(unvoiced[1:])\n",
    "    unvoiced_segment.export(f\"{i}unvoiced.wav\", format=\"WAV\")\n",
    "    \n",
    "    \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
